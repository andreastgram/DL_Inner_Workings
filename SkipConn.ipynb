{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time\n",
    "\n",
    "import idlmam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available(): \n",
    "    device = torch.device(\"mps\") \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.FashionMNIST(\"./\", train=True, transform=transforms.ToTensor(), download=True) \n",
    "test_data = torchvision.datasets.FashionMNIST(\"./\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True) \n",
    "test_loader = DataLoader(test_data, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, H = 28, 28 # Width and Height of the image\n",
    "D = 28 * 28   # Dimension of the image\n",
    "n = 256       # Number of neurons in the hidden layer\n",
    "C = 1         # Number of channels\n",
    "\n",
    "n_filters = 32\n",
    "\n",
    "classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipFC(nn.Module):\n",
    "    def __init__(self, n_layers, in_size, out_size, leak_rate=0.1):\n",
    "        \"\"\"\n",
    "        n_layers: how many hidden layers for this block of dense skip connections\n",
    "        in_size: how many features are coming into this layer\n",
    "        out_size: how many features should be used for the final layer of this block.  \n",
    "        leak_rate: the parameter for the LeakyReLU activation function. \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        #The final layer will be treated differently, so lets grab it's index to use in the next two lines\n",
    "        l = n_layers-1\n",
    "        #The linear and batch norm layers are stored in `layers` and `bns` respectively. A list comprehensive creates all the layers in one line each. The `if i == l` allows us to single out the last layer which needs to use `out_size` instead of `in_size`\n",
    "        self.layers = nn.ModuleList([nn.Linear(in_size*l, out_size) if i == l else nn.Linear(in_size, in_size) for i in range(n_layers)])\n",
    "        self.bns = nn.ModuleList([nn.BatchNorm1d(out_size) if i == l else nn.BatchNorm1d(in_size) for i in range(n_layers)])\n",
    "        #Since we are writing our own `forward` function instead of using nn.Sequential, we can just use one activation object multiple times. \n",
    "        self.activation = nn.LeakyReLU(leak_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #First we need a location to store the activations from every layer (except the last one) in this block. All the activations will be combined as the input to the last layer, which is what makes the skips! \n",
    "        activations = []\n",
    "        \n",
    "        #zip the linear and normalization layers into paired tuples, using [:-1] to select all but the last item in each list.\n",
    "        for layer, bn in zip(self.layers[:-1], self.bns[:-1]):\n",
    "            x = self.activation(bn(layer(x)))\n",
    "            activations.append( x )\n",
    "        #concatenate the activations together, this makes the input for the last layer\n",
    "        x = torch.cat(activations, dim=1)\n",
    "        #Now manually use the last linear and batch-norm layer on this concatenated input, giving us the result.\n",
    "        return self.activation(self.bns[-1](self.layers[-1](x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_skip_model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    SkipFC(2, D, n),\n",
    "    SkipFC(2, n, n),\n",
    "    SkipFC(2, n, n),\n",
    "    nn.Linear(n, classes),\n",
    ")\n",
    "\n",
    "fc_skip_results = idlmam.train_network(fc_skip_model, loss_func, train_loader, test_loader=test_loader, epochs=10, score_funcs={'Accuracy': accuracy_score}, device=device)\n",
    "del fc_skip_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip connection for the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipConv2d(nn.Module):\n",
    "    def __init__(self, n_layers, in_channels, out_channels, kernel_size=3, leak_rate=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        #The last convolution will have a different number of inputs and output channels, so we still need that index\n",
    "        l = n_layers-1\n",
    "        #this is just simple helper values \n",
    "        f = (kernel_size, kernel_size)\n",
    "        pad = (kernel_size-1)//2\n",
    "        \n",
    "        #Defining the layers used, altering the construction of the last layer using the same `if i == l` list comprehension. We are going to combine convolutions via their channels, so the in and out channels change for the last layer.  \n",
    "        self.layers = nn.ModuleList([nn.Conv2d(in_channels*l, out_channels, kernel_size=f, padding=pad) if i == l else nn.Conv2d(in_channels, in_channels, kernel_size=f, padding=pad) for i in range(n_layers)])\n",
    "        self.bns = nn.ModuleList([nn.BatchNorm2d(out_channels) if i == l else nn.BatchNorm2d(in_channels) for i in range(n_layers)])\n",
    "        \n",
    "        self.activation = nn.LeakyReLU(leak_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #This code is identical to the SkipFC class, but its worth highliting the most important line that could change. \n",
    "        activations = []\n",
    "        \n",
    "        for layer, bn in zip(self.layers[:-1], self.bns[:-1]):\n",
    "            x = self.activation(bn(layer(x)))\n",
    "            activations.append( x )\n",
    "        #Which is the concatination of all the activations here. Our tensors are organized as (B, C, W, H), which is the default in PyTorch. But you can change that, and sometimes people use (B, W, H, C). In that situation the C channel is at index 3 instead of 1. So you would change `cat=3` in that scenario. This is also how you would adapt this code to work with RNNs\n",
    "        x = torch.cat(activations, dim=1)\n",
    "        \n",
    "        return self.activation(self.bns[-1](self.layers[-1](x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_skip_model = nn.Sequential(\n",
    "    nn.Conv2d(C, n_filters, (3,3), padding=1), \n",
    "    SkipConv2d(3, n_filters, 2*n_filters),\n",
    "    nn.MaxPool2d((2,2)),\n",
    "    nn.LeakyReLU(),\n",
    "    SkipConv2d(3, 2*n_filters, 4*n_filters),\n",
    "    nn.MaxPool2d((2,2)),\n",
    "    SkipConv2d(2, 4*n_filters, 4*n_filters),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(D*n_filters//4, classes),\n",
    ")\n",
    "\n",
    "cnn_skip_results = idlmam.train_network(cnn_skip_model, loss_func, train_loader, test_loader=test_loader, epochs=10, score_funcs={'Accuracy': accuracy_score}, device=device)\n",
    "del cnn_skip_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info share block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infoShareBlock(n_filters): \n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(n_filters, n_filters, (1,1), padding=0), \n",
    "        nn.BatchNorm2d(n_filters), \n",
    "        nn.LeakyReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnnLayer(in_filters, out_filters=None, kernel_size=3):\n",
    "    if out_filters is None:\n",
    "        out_filters = in_filters #This is a common pattern, so lets automate it as a default if not asked\n",
    "    padding=kernel_size//2 #padding to stay the same size\n",
    "    return nn.Sequential( # Combine the layer and activation into a single unit\n",
    "        nn.Conv2d(in_filters, out_filters, kernel_size, padding=padding), \n",
    "        nn.BatchNorm2d(out_filters), #The only change, adding BatchNorm2d after our convolution! \n",
    "        nn.LeakyReLU(leak_rate)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_1x1_model = nn.Sequential(\n",
    "    cnnLayer(C, n_filters), \n",
    "    cnnLayer(n_filters),\n",
    "    infoShareBlock(n_filters), #first info block after 2x cnnLayers\n",
    "    cnnLayer(n_filters),\n",
    "    nn.MaxPool2d((2,2)),\n",
    "    cnnLayer(n_filters, 2*n_filters), \n",
    "    cnnLayer(2*n_filters),\n",
    "    infoShareBlock(2*n_filters),\n",
    "    cnnLayer(2*n_filters), \n",
    "    nn.MaxPool2d((2,2)),\n",
    "    cnnLayer(2*n_filters, 4*n_filters), \n",
    "    cnnLayer(4*n_filters),\n",
    "    infoShareBlock(4*n_filters),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(D*n_filters//4, classes),\n",
    ")\n",
    "#Now train up this model\n",
    "cnn_1x1_results = idlmam.train_network(cnn_1x1_model, loss_func, train_loader, test_loader=test_loader, epochs=10, score_funcs={'Accuracy': accuracy_score}, device=device)\n",
    "del cnn_1x1_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(x='epoch', y='test Accuracy', data=cnn_relu_results, label='CNN-ReLU')\n",
    "# sns.lineplot(x='epoch', y='test Accuracy', data=cnn_bn_results, label='CNN-ReLU-BN')\n",
    "sns.lineplot(x='epoch', y='test Accuracy', data=cnn_1x1_results, label='CNN-ReLU-BN-1x1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we combine skip and 1 x 1 convs we get residual connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockE(nn.Module):\n",
    "    def __init__(self, channels, kernel_size=3, leak_rate=0.1):\n",
    "        \"\"\"\n",
    "        channels: how many channels are in the input/output to this layer\n",
    "        kernel_size: how large of a filter should we use\n",
    "        leak_rate: paramter for the LeakyReLU activation function\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        #how much padding will our convolutional layers need to maintain the input shape\n",
    "        pad = (kernel_size-1)//2\n",
    "        \n",
    "        #Define the conv an BN layers we will use in a sub-network, just 2 hidden layers of conv/BN/activation\n",
    "        self.F = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, kernel_size, padding=pad),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.LeakyReLU(leak_rate),\n",
    "            nn.Conv2d(channels, channels, kernel_size, padding=pad),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.LeakyReLU(leak_rate),\n",
    "        )\n",
    "     \n",
    "    def forward(self, x):\n",
    "        return x + self.F(x) #F() has all the work for the long path, we just add it to the input\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a way to handle different numbers of channels after we do pooling. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's what residual bottlenecks are for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBottleNeck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, leak_rate=0.1):\n",
    "        super().__init__()\n",
    "        #how much padding will our convolutional layers need to maintain the input shape\n",
    "        pad = (kernel_size-1)//2\n",
    "        #The botteneck should be smaller, so output/4 or input. You could also try changing max to min, its not a major issue. \n",
    "        bottleneck = max(out_channels//4, in_channels)\n",
    "        #Define the three sets of BN and convolution layers we need. \n",
    "        #Notice that for the 1x1 convs we use padding=0, because 1x1 will not change shape! \n",
    "        self.F = nn.Sequential(\n",
    "            #Compress down\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.LeakyReLU(leak_rate),\n",
    "            nn.Conv2d(in_channels, bottleneck, 1, padding=0),\n",
    "            #Normal layer doing a full conv\n",
    "            nn.BatchNorm2d(bottleneck),\n",
    "            nn.LeakyReLU(leak_rate),\n",
    "            nn.Conv2d(bottleneck, bottleneck, kernel_size, padding=pad),\n",
    "            #Expand back up\n",
    "            nn.BatchNorm2d(bottleneck),\n",
    "            nn.LeakyReLU(leak_rate),\n",
    "            nn.Conv2d(bottleneck, out_channels, 1, padding=0)\n",
    "        )\n",
    "\n",
    "        #By default, our shortcut will be the identiy function - which simply returns the input as the output\n",
    "        self.shortcut = nn.Identity()\n",
    "        #If we need to change the shape, then lets turn the shortcut into a small layer with 1x1 conv and BM\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut =  nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, out_channels, 1, padding=0), \n",
    "                    nn.BatchNorm2d(out_channels)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # shortcut(x) plays the role of \"x\", do as little work as possible to keep the tensor shapes the same.\n",
    "        return self.shortcut(x) + self.F(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_res_model = nn.Sequential(\n",
    "    ResidualBottleNeck(C, n_filters), #BottleNeck to start because we need more channels. Its also common to start with just one normal hidden layer before starting residual blocks. \n",
    "    nn.LeakyReLU(leak_rate), #We are inserting a activation after each residual. This is optional. \n",
    "    ResidualBlockE(n_filters),\n",
    "    nn.LeakyReLU(leak_rate),\n",
    "    nn.MaxPool2d((2,2)),\n",
    "    ResidualBottleNeck(n_filters, 2*n_filters),\n",
    "    nn.LeakyReLU(leak_rate),\n",
    "    ResidualBlockE(2*n_filters),\n",
    "    nn.LeakyReLU(leak_rate),\n",
    "    nn.MaxPool2d((2,2)),\n",
    "    ResidualBottleNeck(2*n_filters, 4*n_filters),\n",
    "    nn.LeakyReLU(leak_rate),\n",
    "    ResidualBlockE(4*n_filters),\n",
    "    nn.LeakyReLU(leak_rate),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(D*n_filters//4, classes),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_res_results = idlmam.train_network(cnn_res_model, \n",
    "                                loss_func, \n",
    "                                train_loader, \n",
    "                                test_loader=test_loader, \n",
    "                                epochs=10, \n",
    "                                score_funcs={'Accuracy': accuracy_score}, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='epoch', y='test Accuracy', \n",
    "             data=cnn_res_results, \n",
    "             label='CNN-ReLU-BN-Res')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
